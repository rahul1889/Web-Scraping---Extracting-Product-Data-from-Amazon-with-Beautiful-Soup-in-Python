{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f617ec93",
   "metadata": {},
   "source": [
    "# Amazon Web scraping using Beautiful Soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "5d9d8812",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "d4eb22db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to extract product title\n",
    "\n",
    "def get_title(soup):\n",
    "    \n",
    "    try:\n",
    "        #outer tag object\n",
    "        title = soup.find(\"span\", attrs= {\"id\": 'productTitle'})\n",
    "        \n",
    "        #inner navigatable string object\n",
    "        title_value = title.text\n",
    "        \n",
    "        #Title as string value\n",
    "        title_string = title_value.strip()\n",
    "        \n",
    "    except AttributeError:\n",
    "        title_string = \"\"\n",
    "        \n",
    "    return title_string\n",
    "\n",
    "\n",
    "#Function to extract Product_Price\n",
    "\n",
    "def Product_Price(soup):\n",
    "    try:\n",
    "        whole_price = soup.find(\"span\", attrs={\"class\": 'a-price-whole'}).text\n",
    "        \n",
    "        fraction_price = soup.find(\"span\", attrs={\"class\": 'a-price-fraction'}).text\n",
    "        \n",
    "        Product_Price = whole_price + fraction_price\n",
    "        \n",
    "    except:\n",
    "        \n",
    "        try:\n",
    "            whole_price = soup.find(\"span\", attrs={\"class\": 'a-price-whole'}).text\n",
    "        \n",
    "            Product_Price = whole_price\n",
    "            \n",
    "        except:\n",
    "            Product_Price = \"\"\n",
    "        \n",
    "    return Product_Price\n",
    "        \n",
    "    \n",
    "#Function to extract Product_rating\n",
    "\n",
    "def Product_rating(soup):\n",
    "    try:\n",
    "        Product_rating = soup.find(\"span\", attrs={\"class\": 'a-size-base a-color-base'}).text.strip()\n",
    "        \n",
    "    except AttributeError:\n",
    "        Product_rating = \"\"\n",
    "        \n",
    "    return Product_rating\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82255315",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "2d9c5012",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "\n",
    "    #HTML URL to to be used to extract data from\n",
    "    URL = \"https://www.amazon.co.uk/s?k=jackets+for+men&crid=28L86GYH7MBJG&sprefix=jackets+for+men%2Caps%2C129&ref=nb_sb_noss_1\"\n",
    "\n",
    "\n",
    "    #Headers for requests\n",
    "    HEADERS = ({'User_Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36', 'Accept_Language': 'en-US, en;q=0.5'})\n",
    "\n",
    "    #HTTP request\n",
    "    webpage = requests.get(URL, headers=HEADERS)\n",
    "\n",
    "    #Soup object containing all data\n",
    "    soup = BeautifulSoup(webpage.content, \"html.parser\")\n",
    "\n",
    "    #Fetch links as list of tag object\n",
    "    Links = soup.find_all(\"a\", attrs={'class':'a-link-normal s-no-outline'})\n",
    "\n",
    "    #store the link\n",
    "    Links_list = []\n",
    "\n",
    "    #loop for extracting links from Tag objects\n",
    "    for link in Links:\n",
    "        Links_list.append(link.get('href'))\n",
    "\n",
    "\n",
    "    d = {\"title\":[], \"price\":[], \"rating\":[]}\n",
    "\n",
    "    #loop for extracting product details from each link\n",
    "\n",
    "    for link in Links_list:\n",
    "        new_webpage = requests.get(\"https://www.amazon.co.uk\" + link, headers=HEADERS)\n",
    "        \n",
    "        new_soup = BeautifulSoup(new_webpage.content, \"html.parser\")\n",
    "\n",
    "\n",
    "        d['title'].append(get_title(new_soup))\n",
    "        d['price'].append(Product_Price(new_soup))\n",
    "        d['rating'].append(Product_rating(new_soup))\n",
    "\n",
    "    amazon_df = pd.DataFrame.from_dict(d)\n",
    "    amazon_df['title'].replace('', np.nan, inplace = True)\n",
    "    amazon_df = amazon_df.dropna(subset=['title'])\n",
    "    amazon_df.to_csv(\"amazon_data.csv\", header =True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bcef110",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf008257",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
